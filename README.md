# Mixed In AI

An industryâ€‘level alternative to Mixed In Key â€” a crossâ€‘platform Electron + Python desktop app for DJs that analyzes audio files and automatically detects musically significant information like Hot Cues, DJ Cues, musical key, BPM, vocals, chorus/hook, and song structure.


## âœ¨ Whatâ€™s inside

- AIâ€‘driven cue intelligence (genreâ€‘aware, beatâ€‘aligned, energy + harmonic signals)
- Full Hot Cue system (Aâ€“E) inspired by pro workflows
- Modular, conflictâ€‘aware pipeline (stages for beats, structure, chorus/hook, bridge)
- Detailed confidence, reason, and tier on every cue for explainability
- Modern UI showing DJ Cues and Hot Cues sideâ€‘byâ€‘side with playback


## ğŸ”¥ Hot Cues (Aâ€“E)

Hot Cues are generated from the final merged cue set and mapped as follows:

- A = Intro (first musical start after silence; beatâ€‘aligned)
- B = First Vocal / Verse (prefer before main drop; fallback: first chorus)
- C = Chorus (prefer first chorus after drop; fallback: next vocal)
- D = Drop (main energy peak; confidence + position scoring; beatâ€‘snapped)
- E = Outro (last structured ending; fallback: last phrase/end)

Quality guarantees:

- Alias matching (intro/mix_in, chorus/hook, drop/climax, outro/mix_out, vocal/verse)
- Minimum spacing of 6s to avoid clustering
- Backfill to reach five anchors whenever the music allows

Implementation: `src/backend/pipeline/hotcue_stage.py`


## ğŸ§  Pipeline architecture

Stages live in `src/backend/pipeline/` and communicate via a normalized dictionary:

- `autocue_stage.py` â€” optional external intro/outro hints (safe fallbacks)
- `aubio_stage.py` â€” onset and beat detection (with `librosa` fallback)
- `pyaudio_stage.py` â€” boundary detection via pyAudioAnalysis (RMS fallback)
- `analyzer_stage.py` â€” wraps the main analyzer (drops, vocals, sections)
+- `chorus_hook_stage.py` â€” harmonic centroid + spectral contrast (chorus/hook)
- `bridge_energy_gap.py` â€” energy valley detection (bridge/energy gap)
- `hotcue_stage.py` â€” maps final cues to Aâ€“E Hot Cues (spacing + backfill)
- `pipeline.py` â€” orchestrator: priority merge, conflict resolution, selective beatâ€‘snapping, validity rules, logs

Pipeline output:

```json
{
  "cues": [...],         // final DJ Cue set
  "hotcues": [...],      // Aâ€“E hot cues
  "beatgrid": [...],
  "duration": 210.32,
  "stages": {...},       // perâ€‘stage outputs
  "logs": [...]          // merge/snap decisions
}
```


## ğŸ› ï¸ Install

Prereqs: Node.js v16+, Python 3.8+

```bash
npm install
pip install -r requirements.txt
```


## â–¶ï¸ Run

Dev (Electron + React):

```bash
npm run dev
```

CLI analyzer test:

```bash
python -m src.backend.test_analyzer /path/to/track.mp3
```


## ğŸ“¦ Project structure

```
src/
â”œâ”€ main.js                # Electron main process
â”œâ”€ preload.js             # IPC bridge
â”œâ”€ renderer/              # React UI (DJ Cues + Hot Cues)
â””â”€ backend/               # Python analyzer + pipeline
   â”œâ”€ analyzer.py
   â””â”€ pipeline/
      â”œâ”€ autocue_stage.py
      â”œâ”€ aubio_stage.py
      â”œâ”€ pyaudio_stage.py
      â”œâ”€ analyzer_stage.py
      â”œâ”€ chorus_hook_stage.py
      â”œâ”€ bridge_energy_gap.py
      â”œâ”€ hotcue_stage.py
      â””â”€ pipeline.py
```


## ğŸ§ª Features (highâ€‘level)

- Key detection (Camelot), multiâ€‘algo BPM, energy profile
- Genreâ€‘adaptive intro/drop; phrase detection (8/16 bars)
- Harmonic cue alignment (tension peaks / stability windows)
- MFCC vocal gate (ZCR + band ratios + H/P ratio)
- Confidence, tier, and reason labeling for every cue


## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make changes with tests if applicable
4. Open a pull request


## ğŸ“„ License

MIT


## ğŸ”— Links

- Repo: `https://github.com/Paradox-455M/MixedInKey`

